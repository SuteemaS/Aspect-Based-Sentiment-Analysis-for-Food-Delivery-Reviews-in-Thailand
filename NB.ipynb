{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Library\" data-toc-modified-id=\"Import-Library-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Library</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>EDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Drop-columns\" data-toc-modified-id=\"Drop-columns-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Drop columns</a></span></li><li><span><a href=\"#Check-Missing-Value\" data-toc-modified-id=\"Check-Missing-Value-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Check Missing Value</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Naive Bayes</a></span></li><li><span><a href=\"#Sentiment\" data-toc-modified-id=\"Sentiment-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Sentiment</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import pythainlp\n",
    "from pythainlp.corpus.common import thai_words\n",
    "from pythainlp.tokenize import dict_trie, word_tokenize\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"final/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    temp = pd.read_csv(filename)\n",
    "    company = filename.split(\"/\")[1].split(\"_\")[0]\n",
    "    temp[\"company\"] = company\n",
    "    df = df.append(temp,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Food Delivery</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>16:30:40</td>\n",
       "      <td>pinkzaa_zaa</td>\n",
       "      <td>ใช้แต่ #LINEMAN มาตลอด\\n______________________...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Company</td>\n",
       "      <td>Positive</td>\n",
       "      <td>LINEMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>11:29:02</td>\n",
       "      <td>roseapple110</td>\n",
       "      <td>มีคนเจอปัญหาไรเดอร์โทรหาไม่ติดตอนที่ปิดแอปทิ้ง...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employee</td>\n",
       "      <td>Negative</td>\n",
       "      <td>LINEMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>18:58:12</td>\n",
       "      <td>twitneearoi</td>\n",
       "      <td>เมนูโปรดของแมวอ้วนอย่างเรา วันนี้ขอเสนออออ \"ข้...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINEMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>17:08:50</td>\n",
       "      <td>belloir_sj</td>\n",
       "      <td>ขั้นกว่าของการเลี้ยงหมี คือการอาบน้ำด้วย #แลคต...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINEMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>16:23:15</td>\n",
       "      <td>ifiend_</td>\n",
       "      <td>แต่ #lineman โปรลดเข้าร่วมเยอะกว่านะ</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Price</td>\n",
       "      <td>Positive</td>\n",
       "      <td>LINEMAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time      username  \\\n",
       "0  2020-08-23  16:30:40   pinkzaa_zaa   \n",
       "1  2020-08-23  11:29:02  roseapple110   \n",
       "2  2020-08-22  18:58:12   twitneearoi   \n",
       "3  2020-08-22  17:08:50    belloir_sj   \n",
       "4  2020-08-22  16:23:15       ifiend_   \n",
       "\n",
       "                                               tweet Food Delivery    Aspect  \\\n",
       "0  ใช้แต่ #LINEMAN มาตลอด\\n______________________...           Yes   Company   \n",
       "1  มีคนเจอปัญหาไรเดอร์โทรหาไม่ติดตอนที่ปิดแอปทิ้ง...           Yes  Employee   \n",
       "2  เมนูโปรดของแมวอ้วนอย่างเรา วันนี้ขอเสนออออ \"ข้...            No       NaN   \n",
       "3  ขั้นกว่าของการเลี้ยงหมี คือการอาบน้ำด้วย #แลคต...            No       NaN   \n",
       "4               แต่ #lineman โปรลดเข้าร่วมเยอะกว่านะ           Yes     Price   \n",
       "\n",
       "  Sentiment  company  \n",
       "0  Positive  LINEMAN  \n",
       "1  Negative  LINEMAN  \n",
       "2       NaN  LINEMAN  \n",
       "3       NaN  LINEMAN  \n",
       "4  Positive  LINEMAN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"date\",\"time\",\"username\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet               0\n",
       "Food Delivery       0\n",
       "Aspect           3339\n",
       "Sentiment        3340\n",
       "company             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet            0\n",
       "Food Delivery    0\n",
       "Aspect           0\n",
       "Sentiment        0\n",
       "company          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add word in dict\n",
    "custom_dict = set(thai_words())\n",
    "\n",
    "System_ = 'ปิด ปิดร้าน ชั่วคราว ระบบ เงิน ตัด บัตร แคนเซิล ยกเลิก เป็น อาราย อะไร พัง ค้าง ล่ม เสีย สั่ง หา ไม่ได้ เด้ง รอนาน รอ ออเดอร์ พัฒนา ตัดเงิน ตัดบัตร หักเงิน แอป แอพ ปัก ปักหมุด พิกัด ใช้ ยาก ง่าย พัฒนา ไม่ตรง แผนที่ โอน เครดิต คืน รีบ แก้ ด่วน ขัดข้อง ฟื้น แก้ไข จ่ายเงิน ปัญหา ไม่เปิด ไม่เจอ แท็ก คืนเงิน ไม่พบ หา โดนระงับ ตรวจสอบ ขั้นตอน หักตังค์ เงินไม่เข้า เติมเงิน ไม่เข้า จ่ายไม่ได้ แผนที่ แบบใหม่ แบบเก่า แมพ พิกัด บัตรเครดิต บัค ฟีเจอร์ บั๊ก หมุน'\n",
    "System_Aspect = System_.split(' ')\n",
    "\n",
    "Company_ = 'คอลเซนเตอร์ คอลเซ็นเตอร์ รับผิดชอบ เบอร์ ติดต่อ สื่อสาร โทร เมล ยกเลิก เงินคืน ร้องเรียน ไม่ สนใจ เพิกเฉย รอสาย ตัดสาย บริการ ด่วน เมล โทร ศูนย์บริการ เจ้าหน้าที่ ปัญหา ชดเชย เลิกใช้ แบน บริษัท โกงเงิน บัญชี เลิกใช้ แคนเซิล ออเดอร์ ลบ องค์กร ระงับ เลิกสั่ง ประทับใจ โกง รีฟัน แนะนำ ชี้แจง แจ้ง รีวิว คอมเพลน'\n",
    "Company_Aspect = Company_.split(' ')\n",
    "\n",
    "Price_ =  'ราคา ค่าส่ง ส่วนลด โปรโมชั่น คุ้มค่า ไม่คุ้ม แพง ถูก ลด โปร บอกต่อ คุ้ม ค่าบริการ ใช้ไม่ได้ ใช้งานไม่ได้ คุณภาพ ใช้ได้ ซื้อ ขั้นต่ำ ส่งฟรี แกง บาท ส่วนต่าง ลูกค้า ใหม่ เก่า โค้ด เพิ่ม ฟรี ค่าอาหาร ค่าจอดรถ ต่ำกว่า รหัส ภาษี คำสั่งซื้อ เสียเงินเพิ่ม สังน้อย บวกเพิ่ม ขนาดเล็ก ค่าธรรมเนียม แถม เก็บ เล็ก คูปอง หมด เต็ม กด ทัน'\n",
    "\n",
    "Price_Aspect = Price_.split(' ')\n",
    "\n",
    "Employee_ = 'ยกเลิก รอ ช้า นาน ชั่วโมง ชม นาที ไม่ได้รับ ไม่ได้อาหาร ปัญหา รอเพิ่ม ออเดอร์ ผู้ส่ง พนักงาน คนขับ คนส่ง อบรม มารยาท คำพูด รอนาน บริการ นิสัย เละเทะ ไม่รับ สาย ส่ง ไรเดอร์ เสีย คน ติดต่อ ไม่ครบ ขาด หาย ช้า ไม่ครบ คนส่ง พนง สุภาพ นาที ไว ส่ง จัดส่ง ซ้อน ยังไม่ได้ ตั้งแต่ บอกทาง เหวี่ยง ส่งผิด ผิด ปฏิเสธ พี่ พูดเพราะ รับงาน ที่อยู่ หาย คุณ ไม่พอใจ น้อง คุ๊น ด่า เชค เช็ค ตรวจ สภาพ พ่วง ขอบคุณ โทร แซง คิว'\n",
    "\n",
    "Employee_Aspect = Employee_.split(' ')\n",
    "\n",
    "reviews_dict = System_Aspect+Company_Aspect+Price_Aspect+Employee_Aspect\n",
    "\n",
    "for word in reviews_dict:\n",
    "    custom_dict.add(word)\n",
    "\n",
    "trie = dict_trie(dict_source= custom_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    \n",
    "    #remove hashtag\n",
    "    hashtag_removed = re.sub(r\"#\\w+\",'', text) \n",
    "    \n",
    "    #remove url\n",
    "    url_removed = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','', hashtag_removed)\n",
    "    \n",
    "    #word tokenize\n",
    "    word_tokenized = pythainlp.word_tokenize(url_removed,custom_dict=trie,keep_whitespace=False,engine='pyicu')\n",
    "    \n",
    "    #thai filter\n",
    "    word_thai = []\n",
    "    for word in word_tokenized:\n",
    "        if pythainlp.util.isthai(word):\n",
    "            for punc in string.punctuation:\n",
    "                word = word.replace(punc,'')\n",
    "            if word != '':\n",
    "                word_thai.append(word)\n",
    "                \n",
    "    #check vocab\n",
    "    check_vocab = []\n",
    "    for word in word_thai:\n",
    "        if word in custom_dict:\n",
    "            check_vocab.append(word)\n",
    "                \n",
    "    #remove stopword\n",
    "    removed_stopword = []\n",
    "    for word in check_vocab:\n",
    "        if word not in pythainlp.corpus.common.thai_stopwords():\n",
    "            removed_stopword.append(word)\n",
    "    \n",
    "    \n",
    "    #remove name of company\n",
    "    remove_company_name = []\n",
    "    for word in removed_stopword:\n",
    "        if word not in ['ฟู้ดแพนด้า','แกรป','แกป','ไลน์แมน','แพนด้า']:\n",
    "            remove_company_name.append(word)\n",
    "                \n",
    "    return remove_company_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=preprocessor)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB(fit_prior=True)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df[['Aspect', 'Sentiment']], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function preprocessor at 0x1a23146320>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train['Aspect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Company       1.00      0.04      0.07       110\n",
      "    Employee       0.58      0.88      0.70       224\n",
      "       Price       0.74      0.95      0.83       248\n",
      "      System       0.88      0.22      0.35       106\n",
      "\n",
      "    accuracy                           0.67       688\n",
      "   macro avg       0.80      0.52      0.49       688\n",
      "weighted avg       0.75      0.67      0.59       688\n",
      "\n",
      "[[  4  69  35   2]\n",
      " [  0 196  27   1]\n",
      " [  0  12 236   0]\n",
      " [  0  61  22  23]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test['Aspect'],y_predict))\n",
    "print(confusion_matrix(y_test['Aspect'],y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526     Employee\n",
       "1771    Employee\n",
       "1503       Price\n",
       "3302     Company\n",
       "979      Company\n",
       "          ...   \n",
       "764      Company\n",
       "259     Employee\n",
       "2539      System\n",
       "1161     Company\n",
       "347        Price\n",
       "Name: Aspect, Length: 688, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['Aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect: Company\n",
      "433 433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.90      0.85        49\n",
      "     Neutral       0.73      0.44      0.55        25\n",
      "    Positive       0.75      0.83      0.79        36\n",
      "\n",
      "    accuracy                           0.77       110\n",
      "   macro avg       0.76      0.72      0.73       110\n",
      "weighted avg       0.77      0.77      0.76       110\n",
      "\n",
      "[[44  2  3]\n",
      " [ 7 11  7]\n",
      " [ 4  2 30]]\n",
      "\n",
      "\n",
      "\n",
      "Aspect: Employee\n",
      "891 891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      1.00      0.83       155\n",
      "     Neutral       0.00      0.00      0.00        32\n",
      "    Positive       1.00      0.16      0.28        37\n",
      "\n",
      "    accuracy                           0.72       224\n",
      "   macro avg       0.57      0.39      0.37       224\n",
      "weighted avg       0.66      0.72      0.62       224\n",
      "\n",
      "[[155   0   0]\n",
      " [ 32   0   0]\n",
      " [ 31   0   6]]\n",
      "\n",
      "\n",
      "\n",
      "Aspect: Price\n",
      "1010 1010\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.50      0.61        66\n",
      "     Neutral       0.63      0.78      0.70       106\n",
      "    Positive       0.73      0.70      0.71        76\n",
      "\n",
      "    accuracy                           0.68       248\n",
      "   macro avg       0.71      0.66      0.67       248\n",
      "weighted avg       0.70      0.68      0.68       248\n",
      "\n",
      "[[33 29  4]\n",
      " [ 7 83 16]\n",
      " [ 3 20 53]]\n",
      "\n",
      "\n",
      "\n",
      "Aspect: System\n",
      "418 418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.69      1.00      0.81        72\n",
      "     Neutral       1.00      0.03      0.06        33\n",
      "    Positive       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69       106\n",
      "   macro avg       0.56      0.34      0.29       106\n",
      "weighted avg       0.78      0.69      0.57       106\n",
      "\n",
      "[[72  0  0]\n",
      " [32  1  0]\n",
      " [ 1  0  0]]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models_raw = {}\n",
    "#smote = SMOTE()\n",
    "\n",
    "for aspect in ['Company','Employee','Price','System']:\n",
    "    \n",
    "    print('Aspect:', aspect)\n",
    "    \n",
    "    pipeline_raw = Pipeline([\n",
    "        ('bow', CountVectorizer(analyzer=preprocessor)),  # strings to token integer counts\n",
    "        ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "        ('classifier',MultinomialNB(fit_prior=True))])  # train on TF-IDF vectors \n",
    "    \n",
    "    X_train_raw = X_train[y_train['Aspect'] == aspect]\n",
    "    y_train_raw = y_train['Sentiment'][y_train['Aspect'] == aspect]\n",
    "    print(len(X_train_raw), len(y_train_raw))\n",
    "    \n",
    "#     #Upsampling\n",
    "#     X_train_raw_up, y_train_raw_up = smote.fit_sample(X_train_raw, y_train_raw)\n",
    "#     print(len(X_train_raw_up), len(y_train_raw_up))\n",
    "    \n",
    "    pipeline_raw.fit(X_train_raw, y_train_raw)\n",
    "    models_raw[aspect] = pipeline_raw\n",
    "    \n",
    "    y_predict_raw = pipeline_raw.predict(X_test[y_test['Aspect'] == aspect])\n",
    "    \n",
    "    print(classification_report(y_test['Sentiment'][y_test['Aspect'] == aspect],y_predict_raw))\n",
    "    print(confusion_matrix(y_test['Sentiment'][y_test['Aspect'] == aspect],y_predict_raw))\n",
    "    print('\\n'*2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
